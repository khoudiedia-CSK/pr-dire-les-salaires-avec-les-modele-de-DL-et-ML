
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Chargement des donn√©es
df = pd.read_csv('jobs_in_data.csv')

# Afficher un aper√ßu
print(df.head())

# -------------------------
# 1. Nettoyage & s√©lection des colonnes
# -------------------------

# On va garder uniquement les colonnes importantes pour pr√©dire le salaire
# Je retire : work_year (toutes les donn√©es sont sur 2022/2023), salary (car on utilise salary_in_usd),
# on garde salary_in_usd comme target

features = [
    'job_title',
    'job_category',
    'salary_currency',    # utile pour v√©rifier si on a bien salary_in_usd coh√©rent
    'employee_residence',
    'experience_level',
    'employment_type',
    'work_setting',
    'company_location',
    'company_size'
]

X = df[features]
y = df['salary_in_usd']

# -------------------------
# 2. Gestion des outliers sur y
y = y.astype(float)
upper_limit = y.quantile(0.99)
y_clipped = y.clip(upper=upper_limit)

# 3. Encodage des variables cat√©gorielles
cat_cols = X.columns.tolist()

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)
    ]
)


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# 1. Charger les donn√©es (si ce n‚Äôest pas d√©j√† fait)
df = pd.read_csv('jobs_in_data.csv')

# 2. S√©lection des features et target
X = df.drop(columns=['salary_in_usd'])  # On pr√©dit salary_in_usd
y = df['salary_in_usd']

# 3. S√©paration features cat√©gorielles
cat_cols = X.select_dtypes(include=['object']).columns.tolist()

# 4. Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 5. Pipeline pr√©traitement + mod√®le
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ],
    remainder='passthrough'  # on garde les autres colonnes num√©riques (ici work_year)
)

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', RandomForestRegressor(random_state=42, n_estimators=100))
])

# 6. Entra√Ænement
pipeline.fit(X_train, y_train)

# 7. Pr√©diction et √©valuation
y_pred = pipeline.predict(X_test)
print(f"MSE: {mean_squared_error(y_test, y_pred):.2f}")
print(f"R2 score: {r2_score(y_test, y_pred):.4f}")


import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler

# 1. Pr√©traitement avec OneHotEncoder + passer √† numpy
X_cat_encoded = OneHotEncoder(handle_unknown='ignore').fit_transform(X[cat_cols]).toarray()
X_num = X.drop(columns=cat_cols).values  # num√©rique (work_year)

X_all = np.hstack([X_num, X_cat_encoded])

# 2. Normalisation features
scaler_X = StandardScaler()
X_all_scaled = scaler_X.fit_transform(X_all)

# 3. Normalisation target
scaler_y = StandardScaler()
y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))

# 4. Split train/test
X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(
    X_all_scaled, y_scaled, test_size=0.2, random_state=42
)

# 5. Cr√©er mod√®le Keras simple
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_dl.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)  # sortie continue
])

model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# 6. Entra√Ænement
model.fit(X_train_dl, y_train_dl, epochs=50, batch_size=32, validation_split=0.2)

# 7. √âvaluation
loss, mae = model.evaluate(X_test_dl, y_test_dl)
print(f"Test MAE: {mae:.4f}")

# 8. Pr√©diction exemple (d√©sencodage cible)
y_pred_dl = model.predict(X_test_dl)
y_pred_original = scaler_y.inverse_transform(y_pred_dl)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, r2_score

# 1. Calcul des m√©triques
rmse_ml = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_ml = r2_score(y_test, y_pred_rf)

# 2. Plot
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.4, color='royalblue', edgecolor=None)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', linewidth=2)
plt.title(f"üìò Machine Learning - Pr√©diction vs R√©el\nRMSE: {rmse_ml:.2f}, R¬≤: {r2_ml:.4f}")
plt.xlabel("Salaire r√©el (USD)")
plt.ylabel("Salaire pr√©dit (USD)")
plt.grid(True)
plt.tight_layout()
plt.show()


Ce code Python (avec matplotlib) sert √† visualiser les performances de ton mod√®le de Machine Learning (ML) en tra√ßant un graphe des valeurs r√©elles contre les valeurs pr√©dites.
 Voici ce qu‚Äôil fait √©tape par √©tape :
import matplotlib.pyplot as plt

# Graphique pour ML : R√©el vs Pr√©dit
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='blue', alpha=0.4, label='Pr√©dictions ML')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Id√©al')
plt.xlabel("Salaires r√©els (USD)")
plt.ylabel("Salaires pr√©dits (USD)")
plt.title("ML - R√©el vs Pr√©dit")
plt.legend()
plt.grid(True)
plt.show()


# -------------------------
# 3. Encodage des variables cat√©gorielles
# -------------------------

# Colonnes cat√©gorielles √† encoder
cat_cols = X.columns.tolist()

# On va appliquer OneHotEncoder pour toutes les colonnes cat√©gorielles
# Si trop de cat√©gories, on peut r√©duire ou utiliser un TargetEncoder, mais l√† on fait simple

# Pipeline de transformation des features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_cols)
    ]
)

# -------------------------
# 4. Normalisation des variables num√©riques (aucune variable num√©rique √† transformer dans X)
# Ici, le seul num√©rique est la target y_clipped (le salaire)
# -------------------------

scaler_y = StandardScaler()
y_scaled = scaler_y.fit_transform(y_clipped.values.reshape(-1,1)).flatten()

# -------------------------
# 5. Split train/test
# -------------------------

X_train, X_test, y_train, y_test = train_test_split(
    X, y_scaled, test_size=0.2, random_state=42
)

# -------------------------
# 6. Construction du pipeline complet (juste encodage pour X)
# -------------------------

X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

print(f"X_train shape after encoding: {X_train_transformed.shape}")
print(f"X_test shape after encoding: {X_test_transformed.shape}")

# y_train et y_test sont pr√™ts pour ML/DL (normalis√©s)

# -------------------------
# Tu peux maintenant utiliser X_train_transformed, y_train pour entra√Æner tes mod√®les ML ou DL.
# -------------------------


import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

plt.figure(figsize=(10, 7))

# Scatter ML (Random Forest)
sns.scatterplot(x=y_test, y=y_pred, color='blue', alpha=0.5, label='Pr√©dictions ML (RF)')

# Scatter DL (Deep Learning)
sns.scatterplot(x=y_test, y=y_pred_dl.flatten(), color='green', alpha=0.5, label='Pr√©dictions DL (NN)')

# Droite id√©ale y = x
lims = [min(y_test.min(), y_pred.min(), y_pred_dl.min()), max(y_test.max(), y_pred.max(), y_pred_dl.max())]
plt.plot(lims, lims, 'r--', label='Pr√©diction id√©ale')

plt.xlabel("Salaire r√©el (USD)")
plt.ylabel("Salaire pr√©dit (USD)")
plt.title("Comparaison des pr√©dictions : ML (Random Forest) vs DL (R√©seau Neurones)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

